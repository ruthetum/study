# 컨슈머 (Consumer)

<img width="771" alt="스크린샷" src="https://github.com/ruthetum/study/assets/59307414/836a8892-1dd8-439b-bbc9-dd38307d4e0c">

프로듀서가 전송한 데이터는 카프카 브로커에 적재

컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 진행
- 예를 들어 마케팅 문자를 고객에게 보내는 기능이 있다면 컨슈머는 토픽으로부터 고객 데이터를 가져와서 문자 발송 처리를 진행

## 컨슈머 내부 구조

<img width="802" alt="스크린" src="https://github.com/ruthetum/study/assets/59307414/a095c1fa-4846-48c6-b274-0abe5560f352">

- Fetcher: 리더 파티션으로부터 레코들을 미리 가져와서 대기
- poll(): Fetcher에 있는 레코드들을 리턴하는 레코드
  - completedFetches에서 데이터를 충분히(최대 max.poll.records 만큼) 가져오는 경우 poll 호출
- ConsumerRecords: 처리하고자 하는 레코드들의 모음. 오프셋 포함
  - 처리가 완료된 경우 commit을 통해 처리한 offset을 판단

## 컨슈머 그룹

<img width="1086" alt="스크린샷" src="https://github.com/ruthetum/study/assets/59307414/02ee3a3a-125f-41f7-a5a3-cf28a66dc7f2">

컨슈머 그룹으로 운영하는 방법은 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 카프카의 독특한 방식

컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있음

컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때, 1개의 파티션은 최대 1개의 컨슈머에 할당 가능함

1개 컨슈머는 여러 개의 파티션에 할당될 수 있음. 따라서 컨슈머 그룹의 컨슈머 개수는 가져가고자 하는 토픽의 파티션 개수보다 같거나 작아야 함

#### 컨슈머 그룹의 컨슈머가 파티션 개수보다 많을 경우
1개의 파티션은 최대 1개의 컨슈머에 할당 가능하기 때문에, 파티션을 할당받지 못 하고 유휴 상태로 남는 컨슈머가 존재

파티션을 할당받지 못한 컨슈머는 스레드만 차지하고 실질적인 데이터 처리를 하지 못하므로 애플리케이션 실행에 있어 불필요한 스레드로 남게 됨

### 컨슈머 그룹을 활용하는 이유

<img width="631" alt="스크린샷" src="https://github.com/ruthetum/study/assets/59307414/47da2721-050e-4337-a8cb-714457de0a4b">

운영 서버의 주요 리소스인 CPU, Memory 정보를 수집하는 데이터 파이프라인을 구축

실시간 리소스를 시간 순으로 확인하기 위해 데이터를 엘라스틱서치에 저장하고, 이와 동시에 대용량 적재를 위해 하둡에 적재

만약 카프카를 활용한 파이프라인이 아니라면 서버에서 실행되는 리소스 수집 및 전송 에이터전트는 수집한 리소르를 엘라시틱서치와 하둡에 적재하기 위해 동기적으로 적재 요청

이렇게 동기로 실행되는 에이전트는 엘라스틱서치 또는 하둡 둘 중에 하나에 장애가 발생한다면 더는 적재가 불가능할 수 있음

<img width="805" alt="스크린샷" src="https://github.com/ruthetum/study/assets/59307414/51ed47cd-9cc0-4f18-8d2e-e9e17015aab0">

카프카는 파이프라인을 운영함에 있어 최종 적재되는 저장소의 장애에 유연하게 대응할 수 있도록 각긱 다른 저장소에 저장하는 컨슈머를 다른 컨슈머 그룹으로 묶음으로써 각 저장소의 장애에 격리되어 운영 가능

엘라스틱서치의 장애로 인해 더는 적재하지 못 하더라도 하둡으로 데이터를 적재하는 데에는 문제가 없음

엘라스틱서치의 장애가 해소되면 엘라스틱서치로 적재하는 컨슈머의 컨슈머 그룹은 마지막으로 적재 완료한 데이터 이후부터 다시 적재를 수행하여 최종적으로 정상화 가능

